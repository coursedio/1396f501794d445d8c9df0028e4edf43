WEBVTT

1
00:00:00.008 --> 00:00:03.004
We've seen that sometimes you can classify items based

2
00:00:03.004 --> 00:00:04.009
on the nearest neighbor.

3
00:00:04.009 --> 00:00:08.005
You can also classify based on trends in the data.

4
00:00:08.005 --> 00:00:11.004
But sometimes, you want to classify items based

5
00:00:11.004 --> 00:00:13.008
on many features in the data.

6
00:00:13.008 --> 00:00:17.003
For that, you can use something called Naive Bayes.

7
00:00:17.003 --> 00:00:19.004
Naive Bayes is one of the most popular

8
00:00:19.004 --> 00:00:21.002
machine learning algorithms.

9
00:00:21.002 --> 00:00:24.009
It's naive because it assumes all the predictors

10
00:00:24.009 --> 00:00:27.007
are independent from one another.

11
00:00:27.007 --> 00:00:29.009
So let's go back to our animal shelter.

12
00:00:29.009 --> 00:00:32.004
Imagine we want to classify all the dogs based

13
00:00:32.004 --> 00:00:33.009
on their breeds.

14
00:00:33.009 --> 00:00:35.002
Let's look at the problem using

15
00:00:35.002 --> 00:00:38.001
a Naive Bayes machine learning algorithm.

16
00:00:38.001 --> 00:00:41.007
To start, let's create three classes of dog breeds.

17
00:00:41.007 --> 00:00:45.007
We'll use terrier, hounds, and sport dogs.

18
00:00:45.007 --> 00:00:47.004
Now, for each of these classes,

19
00:00:47.004 --> 00:00:50.008
we'll use three features as predictors.

20
00:00:50.008 --> 00:00:54.009
Let's use hair length, height, and weight.

21
00:00:54.009 --> 00:00:56.006
Remember that some of these predictors

22
00:00:56.006 --> 00:00:59.005
will be closely auto correlated.

23
00:00:59.005 --> 00:01:02.005
A tall dog is more likely to weigh more.

24
00:01:02.005 --> 00:01:04.005
But Naive Bayes considers each one

25
00:01:04.005 --> 00:01:06.006
of these predictors independently.

26
00:01:06.006 --> 00:01:09.007
Remember, that's why it's called naive.

27
00:01:09.007 --> 00:01:11.009
Once you have your classes and predictors set up,

28
00:01:11.009 --> 00:01:13.008
then the Naive Bayes will do something

29
00:01:13.008 --> 00:01:17.001
called class predictor probability.

30
00:01:17.001 --> 00:01:19.005
This is when it looks at each one of the predictors

31
00:01:19.005 --> 00:01:22.006
and creates a probability that the dog belongs

32
00:01:22.006 --> 00:01:24.004
in this class.

33
00:01:24.004 --> 00:01:25.004
So let's see what happens

34
00:01:25.004 --> 00:01:28.000
when we try to identify an unknown dog.

35
00:01:28.000 --> 00:01:30.009
The first predictor we look at is hair length.

36
00:01:30.009 --> 00:01:34.001
The machine learning algorithm checks the probability

37
00:01:34.001 --> 00:01:36.009
of a dog with this hair length belonging

38
00:01:36.009 --> 00:01:38.008
in the three breeds.

39
00:01:38.008 --> 00:01:41.000
It finds that a dog with this hair length

40
00:01:41.000 --> 00:01:43.005
has a 40% chance of being a terrier,

41
00:01:43.005 --> 00:01:45.006
a 10% chance of being a hound,

42
00:01:45.006 --> 00:01:49.005
and a 50% chance that it's a sport dog.

43
00:01:49.005 --> 00:01:52.009
The next thing you check is the unknown dog's height.

44
00:01:52.009 --> 00:01:55.005
It looks at this predictor independently

45
00:01:55.005 --> 00:01:59.005
and tries to calculate the class predictor probability.

46
00:01:59.005 --> 00:02:01.002
So it looks at the training data

47
00:02:01.002 --> 00:02:05.000
and finds that there's a 20% chance that it's a terrier,

48
00:02:05.000 --> 00:02:07.004
a 10% chance it's a hound,

49
00:02:07.004 --> 00:02:11.002
and a 70% chance that it's a sport dog.

50
00:02:11.002 --> 00:02:12.005
The final thing you want to check

51
00:02:12.005 --> 00:02:14.009
is the unknown dog's weight.

52
00:02:14.009 --> 00:02:16.009
This might seem like a strange predictor

53
00:02:16.009 --> 00:02:19.006
because it's closely related to height.

54
00:02:19.006 --> 00:02:23.006
But remember that Naive Bayes is evaluating the probability

55
00:02:23.006 --> 00:02:26.004
of each predictor independently.

56
00:02:26.004 --> 00:02:28.000
It looks at the training data

57
00:02:28.000 --> 00:02:30.009
and finds that there's a 10% chance that it's a terrier,

58
00:02:30.009 --> 00:02:33.000
a 5% chance that it's a hound,

59
00:02:33.000 --> 00:02:36.008
and an 85% chance that it's a sports dog.

60
00:02:36.008 --> 00:02:37.008
So now you have this table

61
00:02:37.008 --> 00:02:41.004
with the unknown dog's class predictor probability.

62
00:02:41.004 --> 00:02:42.005
If you look at it, you can see

63
00:02:42.005 --> 00:02:45.005
that the dog is probably a sport dog.

64
00:02:45.005 --> 00:02:46.003
As you can imagine,

65
00:02:46.003 --> 00:02:48.003
organizations can use Naive Bayes

66
00:02:48.003 --> 00:02:51.004
to do much more than just classify dog breeds.

67
00:02:51.004 --> 00:02:53.004
Banks use it to check for fraud.

68
00:02:53.004 --> 00:02:57.000
They look at each banking predictor independently,

69
00:02:57.000 --> 00:02:59.006
and then measure the likelihood that it's fraud.

70
00:02:59.006 --> 00:03:02.000
Then they use a class predictor probability

71
00:03:02.000 --> 00:03:04.007
to classify the transaction.

72
00:03:04.007 --> 00:03:07.006
Cybersecurity firms also use Naive Bayes

73
00:03:07.006 --> 00:03:09.007
to look for securities threats.

74
00:03:09.007 --> 00:03:12.008
It looks at each threat predictor independently,

75
00:03:12.008 --> 00:03:16.004
and then flags items for security review.

76
00:03:16.004 --> 00:03:17.004
The key thing is that

77
00:03:17.004 --> 00:03:20.004
because Naive Bayes makes so few assumptions,

78
00:03:20.004 --> 00:03:24.000
it can look in an enormous amount of predictors.

79
00:03:24.000 --> 00:03:27.004
Often, these extra predictors make it much more accurate

80
00:03:27.004 --> 00:03:29.000
when classifying your data.
