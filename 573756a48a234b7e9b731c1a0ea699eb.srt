WEBVTT

1
00:00:01.000 --> 00:00:02.006
- When my son was three years old,

2
00:00:02.006 --> 00:00:04.005
we told him that he needed to brush his teeth,

3
00:00:04.005 --> 00:00:07.007
floss, and take a shower before going to bed.

4
00:00:07.007 --> 00:00:09.007
Then one day I got a call from his preschool

5
00:00:09.007 --> 00:00:12.000
that said he wouldn't take a nap unless they provided him

6
00:00:12.000 --> 00:00:15.001
with a shower, toothbrush, and flosser.

7
00:00:15.001 --> 00:00:17.004
I explained to him that it was okay to nap

8
00:00:17.004 --> 00:00:19.002
without following those rules.

9
00:00:19.002 --> 00:00:21.008
He seemed annoyed, but agreed.

10
00:00:21.008 --> 00:00:24.004
The rules we had created for him were too simple.

11
00:00:24.004 --> 00:00:27.004
They worked well at home, but didn't fit well

12
00:00:27.004 --> 00:00:31.008
in the outside world, so we added greater complexity.

13
00:00:31.008 --> 00:00:34.007
He didn't have to follow the rules for preschool naps,

14
00:00:34.007 --> 00:00:38.004
when visiting grandparents, or when flying on an airplane.

15
00:00:38.004 --> 00:00:40.008
Each time we added more variables,

16
00:00:40.008 --> 00:00:44.003
he became more annoyed with the complexity.

17
00:00:44.003 --> 00:00:45.009
In supervised machine learning,

18
00:00:45.009 --> 00:00:48.009
your AI system can run into the same problem.

19
00:00:48.009 --> 00:00:50.007
The system can create simple rules

20
00:00:50.007 --> 00:00:53.006
for its training data that doesn't work well

21
00:00:53.006 --> 00:00:56.004
when looking at the larger test data.

22
00:00:56.004 --> 00:00:58.005
It was like what my son was going through.

23
00:00:58.005 --> 00:01:00.004
What works well at home,

24
00:01:00.004 --> 00:01:03.000
doesn't work well in the outside world.

25
00:01:03.000 --> 00:01:06.008
This challenge is called underfitting the data.

26
00:01:06.008 --> 00:01:10.000
Sometimes data scientists add more complexity,

27
00:01:10.000 --> 00:01:12.008
and then that complexity makes it more difficult

28
00:01:12.008 --> 00:01:14.006
for the system to handle.

29
00:01:14.006 --> 00:01:16.002
This was like all the variables

30
00:01:16.002 --> 00:01:18.006
we added to my son's simple rule.

31
00:01:18.006 --> 00:01:21.009
This is called overfitting the data.

32
00:01:21.009 --> 00:01:23.009
Imagine that you work for a website like Zillow

33
00:01:23.009 --> 00:01:26.007
that matches up buyers and sellers of homes.

34
00:01:26.007 --> 00:01:28.005
One of the key things that you need to do

35
00:01:28.005 --> 00:01:30.009
is estimate the value of the home.

36
00:01:30.009 --> 00:01:33.000
Your machine could use Naive Bayes

37
00:01:33.000 --> 00:01:34.009
to create four predictors,

38
00:01:34.009 --> 00:01:37.001
the square footage, the location,

39
00:01:37.001 --> 00:01:40.001
number of bathrooms, and the number of bedrooms.

40
00:01:40.001 --> 00:01:43.003
That way it could look at each predictor independently

41
00:01:43.003 --> 00:01:46.008
and then compare it to recently sold houses.

42
00:01:46.008 --> 00:01:49.008
Then the system would come up with an accurate estimate.

43
00:01:49.008 --> 00:01:53.001
Now, keep in mind that you're only using four predictors

44
00:01:53.001 --> 00:01:56.001
to train your system on how to estimate.

45
00:01:56.001 --> 00:01:58.009
So the machine is learning from a simple rule.

46
00:01:58.009 --> 00:02:01.008
It's the same as the simple rule to always shower

47
00:02:01.008 --> 00:02:03.007
and brush your teeth before sleeping.

48
00:02:03.007 --> 00:02:05.009
So there's a very good chance this rule

49
00:02:05.009 --> 00:02:08.000
will underfit the data.

50
00:02:08.000 --> 00:02:09.008
It's not going to work well when you look at

51
00:02:09.008 --> 00:02:12.005
hundreds of thousands of homes.

52
00:02:12.005 --> 00:02:17.000
On top of that, housing data usually has a lot of variance.

53
00:02:17.000 --> 00:02:19.006
Remember, that's when your data is spread out.

54
00:02:19.006 --> 00:02:22.002
There's a lot of homes with different prices

55
00:02:22.002 --> 00:02:25.002
that have the same square footage, the same location,

56
00:02:25.002 --> 00:02:27.003
and the same number of bathrooms.

57
00:02:27.003 --> 00:02:30.009
So that makes it difficult to find a close group.

58
00:02:30.009 --> 00:02:35.002
So to fix this, data scientists can create new predictors.

59
00:02:35.002 --> 00:02:38.001
Maybe they'll create predictors for quality of view,

60
00:02:38.001 --> 00:02:42.001
modern appliances, wood floors, or walkability.

61
00:02:42.001 --> 00:02:45.008
This creates a much more complex prediction,

62
00:02:45.008 --> 00:02:48.001
because now your machine needs to balance

63
00:02:48.001 --> 00:02:50.007
a lot more predictors.

64
00:02:50.007 --> 00:02:53.007
So here your rule is overfitting the data.

65
00:02:53.007 --> 00:02:56.007
The system needs to look at a lot more relationships

66
00:02:56.007 --> 00:03:01.000
between these predictors to make an accurate prediction.

67
00:03:01.000 --> 00:03:02.004
The key thing to keep in mind

68
00:03:02.004 --> 00:03:05.005
is there isn't really one way to fix this problem.

69
00:03:05.005 --> 00:03:06.009
When you're training the system,

70
00:03:06.009 --> 00:03:10.003
you need to reach a compromise between simple rules

71
00:03:10.003 --> 00:03:12.008
and giving the rules enough complexity

72
00:03:12.008 --> 00:03:14.006
to make good predictions.

73
00:03:14.006 --> 00:03:18.009
You need to balance unfitting or overfitting the data.
